{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.preprocessing.text as Text\n",
    "import tensorflow.keras.preprocessing.sequence as Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/two-topic-fulltext.pkl')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Set text to lowercase and replace all non-ascii characters with spaces.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "    return text\n",
    "\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "# If tokenized text sequences exist, load as X, else tokenize the dataset and save.\n",
    "my_file = Path(\"./data/text-sequences.npy\")\n",
    "\n",
    "if my_file.is_file():\n",
    "    X = np.load(\"./data/text-sequences.npy\")\n",
    "else:\n",
    "    tokenizer = Text.Tokenizer(num_words=20000,\n",
    "                               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                               lower=True, split=' ', char_level=False,\n",
    "                               oov_token=None)\n",
    "    tokenizer.fit_on_texts(df[\"full_text\"].values)\n",
    "\n",
    "    index_words = tokenizer.word_index\n",
    "    print(f\"Number of words: {len(index_words)}\")\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(df[\"full_text\"].values)\n",
    "\n",
    "    X = Sequence.pad_sequences(X, maxlen=250)\n",
    "\n",
    "    np.save(\"./data/text-sequences.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"topic\"].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0515 20:58:20.013479 139839040452416 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f2cf104ff60>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', min_delta=.0001, patience=2, verbose=True)]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(20_000, 100, input_length=X.shape[1]))\n",
    "model.add(layers.LSTM(100, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15300 samples, validate on 1700 samples\n",
      "Epoch 1/4\n",
      "15296/15300 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.7524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0515 21:10:02.008979 139839040452416 callbacks.py:1004] Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15300/15300 [==============================] - 700s 46ms/sample - loss: 0.5323 - accuracy: 0.7525 - val_loss: 0.4314 - val_accuracy: 0.8282\n",
      "Epoch 2/4\n",
      " 8864/15300 [================>.............] - ETA: 4:57 - loss: 0.3845 - accuracy: 0.8413"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=4, batch_size=32, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"paper_classifier2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"./paper_classifier2.h5\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"accuracy\"], label='train')\n",
    "plt.plot(history.history[\"val_accuracy\"], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"accuracy-text-classifier.png\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], label='train')\n",
    "plt.plot(history.history[\"val_loss\"], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"loss-text-classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predict = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.hist(Y_test_predict[Y_test == 0], alpha = 0.5)\n",
    "plt.hist(Y_test_predict[Y_test == 1], alpha = 0.5)\n",
    "plt.legend([\"Deep Learning\", \"Computer Vision\"])\n",
    "plt.title(\"Prediction Confidence for Both Topics\")\n",
    "plt.show()\n",
    "plt.savefig(\"./results/prediction-confidences.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of uncertain prediction:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'multiple kernel learning for brain-computer interfacing wojciech samek1, alexander binder1, klaus-robert muller1,2 abstract combining information from different sources is a common way to improve classification accuracy in brain- computer interfacing (bci). for instance, in small sample set- tings it is useful to integrate data from other subjects or sessions in order to improve the estimation quality of the spatial filters or the classifier. since data from different subjects may show large variability, it is crucial to weight the contributions according to importance. many multi-subject learning algorithms determine the optimal weighting in a separate step by using heuristics, however, without ensuring that the selected weights are optimal with respect to classification. in this work we apply multiple kernel learning (mkl) to this problem. mkl has been widely used for feature fusion in computer vision and allows to simultaneously learn the classifier and the optimal weighting. we compare the mkl method to two baseline approaches and investigate the reasons for performance improvement. i. introduction extracting robust and informative features from data is a crucial step for successful decoding of the users inten- tion in brain-computer interfacing (bci) [1]. one of the most popular feature extraction methods in bci is common spatial patterns (csp) [2]. it is well suited to discriminate between different mental states induced by motor imagery as it enhances the erd/ers effect [1] by maximizing the dif- ferences in band power between two conditions. since csp is a data driven approach it is prone to overfitting and may provide suboptimal results if data is scarce, non-stationary or affected by artefacts. recently, several extensions have been proposed to robustify the algorithm, e.g. [3], [4], [5], [6], [7], [8], [9]. one of the strategies to improve the estimation quality of the spatial filters is to utilize data from other subjects, e.g. by regularizing the estimated covariance matrix towards the covariance matrices of other users. however, it has been shown [9] that inclusion of other subjects data may harm csp performance if the discriminative subspaces of the different data sets do not match. therefore it is crucial to weight the contributions from other users according to importance1. the optimal weighting is usually computed in a separate step by applying a heuristic, e.g. the composite 1w. samek (wojciech.samek@tu-berlin.de), a. binder (alexander.binder@tu-berlin.de), k.-r. muller (klaus-robert.mueller@tu-berlin.de), are with the berlin institute of technology, marchstr. 23, 10587 berlin, ger- many. 2k.-r. muller is with the department of brain and cognitive engineer- ing, korea university, anam-dong, seongbuk-gu, seoul 136-713, korea *this work was supported by the german research foundation (grk 1589/1), by the federal ministry of education and research (bmbf) under the project adaptive bci (fkz 01gq1115) and by the world class university program through the national research foundation of korea funded by the ministry of education, science, and technology, under grant r31-10008. 1note that this also includes the exclusion of some subjects. csp method (ccsp) [5] uses weights that are proportional to the similarity, measured by kullback-leibler divergence, between subjects. note that such heuristics do not ensure that the selected weights are optimal with respect to classification. in this work we apply multiple kernel learning (mkl) [10], [11] to the data integration problem in bci. this method allows to simultaneously learn the classifier and the optimal weighting and has been successfully applied to the problem of feature fusion in computer vision [12]. note that the mkl approach has been applied to bci before [13], but in a completely different scenario, namely as single subject classifier with different kernels and not for solving the data integration problem. this paper is organized as follows. in the next section we present the multiple kernel learning method and its application to bci. in section iii we compare it with two baseline approaches on a data set of 30 subjects performing motor imagery. we conclude in section iv with a discussion. ii. multiple kernel learning for bci a. multiple kernel learning support vector machines (svm) [14], [15] are binary classifiers that learn a linear decision hyperplane with a separating margin between the two classes e.g. left and right hand motor imagery. they have been widely used in many different areas and can be extended to non-linear decision boundaries by applying the kernel trick. the svm decision function can be written as f(xnew) = n i=1 ik(x i,xnew) + b, (1) where xnew is the trial to be classified, xi is a training trial, k(, ) denotes the kernel function and i and b are param- eters which are determined when training the svm. the integration of data from different sources can be achieved by computing a kernel for each source and combining them. the decision function in this case is f(xnew) = n i=1 i m j=1 jkj(x i,xnew) + b, (2) where j  0 are the kernel weights assigning an importance value to each source j. multiple kernel learning (mkl) [10] simultaneously optimizes for the parameters i, b and j . note that the degree of sparsity of the weight vector  = [1 . . . m] can be controlled by adding a `p-norm constraint ||||p = 1 (see [11], [16] for details). ar x iv :1 31 0. 60 67 v1   [ sta t.m l]   2 2 o ct  20 13 b. application to bci the data integration problem in brain-computer interfac- ing can be solved on different levels. the simplest approach is to pool data extracted from different sources and to apply the learning algorithms to the combined set. an alternative is to train a model on each data set separately, to apply all models to the data of interest and to combine the classifier outputs (see e.g. [17], [18], [19]). finally one can combine the information from different sources on a medium level of representation, namely on the feature level. in this work we propose to perform data integration on this level by computing a set of features and a kernel for each source. multiple kernel learning (mkl) then combines the kernels in a way that is optimal for classification. the application of our method to bci is summarized by figure 1. the core idea of it is to provide different views on the data of interest and to automatically select the important information by combining them in a way that is optimal with respect to classification. in the following we describe our method when training a classifier for subject k. in the first step we compute a set of spatial filters w j = [wj1, . . . ,w j 6] for each subject j (including k) by solving the generalized eigenvalue problem cj1w j i = ic j 2w j i , (3) and selecting three filters wji with largest i and three with smallest i. note that cjc denotes the estimated covariance matrix of class c and subject j. then we apply these filters (including w k) to the data of subject k and compute log- variance features f ji for each trial i as f ji = log(var((w j)>xki )). (4) note that xki is the band-pass filtered eeg data of trial i and subject k. by using filters from other subjects we look at the data of user k through the lens of other subjects. this is advantageous when e.g. spatial filters can not be reliably computed from subjects k data because of artefacts or a small-sample setting. pooling data from all subjects is suboptimal as the different data sets may vary strongly, i.e. only the information contained in a subset of other subjects may be relevant. after this feature extraction step we compute a linear kernel matrix for each view j as kj(f j i ,f j l ) = (f j i ) >f jl . (5) the kernels are then combined and a classifier is learned by solving the following mkl optimization problem min  max  n i=1 i  1 2 n i,l=1 ilyiyl m j=1 jkj(f j i ,f j l ) (6) s.t. ni=1 : 0  i  c; n i=1 yii = 0; mj=1 : j  0; p  1. where m is the number of views, n is the number of training trials, j denotes the kernel weight, yi and yl represent trial labels and i, c are svm parameters. we denote this approach as mklcsp. iii. experimental evaluation a. dataset and experimental setup the experimental evaluation in this work is based on the vital bci data set [20] containing eeg recordings from 80 healthy users performing motor imagery with the left and right hand or with the feet. we restrict our analysis to the 30 subjects performing left hand vs. right hand motor imagery. the data set contains measurements from a calibration and a test session recorded on the same day, the former consists of 150 trials without feedback and latter consists of 300 trials with 1d visual feedback. all subjects in this study are bci novices. the eeg signal was recorded from 119 ag/agcl electrodes, band-pass filtered between 0.05 and 200 hz and downsampled to 100 hz. we manually select a set of 62 electrodes densely covering the motor cortex and extract a time segment located from 750ms to 3500ms after the cue instructing the subject to perform motor imagery. furthermore we band-pass filter the data in 8-30 hz using a 5-th order butterworth filter and use six spatial filters. we compare three algorithms in the experiments, namely csp, ccsp [5] and our novel mklcsp approach. note that csp does not perform data integration and the composite csp (ccsp) method incorporates data from other subjects by regularizing the covariance matrix ckc as c k c = (1 )ckc +  m j=1,j 6=k jc j c with j = 1z  1kl[cjc||ckc ] , z =  l 6=k 1 kl[clc||ckc ] and kl[||] is the kullback-leibler divergence2. in order to allow better comparison we apply two types of classifiers after filtering the data with csp and ccsp, namely linear discriminant analysis (lda) and support vector machine (svm). we use 5-fold cross-validation on the training data to select the relevant parameters and apply lowest error rate as selection criterion. our algorithm has two free pa- rameters, namely the svm regularization parameter c and the norm parameter p. we select c from 10i with i  {2,1.5, . . . , 1.5, 2} and p from {1, 1.125, 1.333, 2,} (as done in [12]). we normalize the kernels by the average diagonal value. for the ccsp method we select  from {0, 105, 104, 103, 102, 0.1, 0.2, . . . , 1}. b. results and evaluation fig. 2 compares the different approaches by using scatter plots. the test error of each subject is represented by a circle. the error rate of the baseline method is represented by the x- coordinate, whereas the y-coordinate denotes the error rate of mklcsp. thus if the circle is below the solid line than our method performs better than the baseline. the mklcsp approach is superior to the csp baseline methods and it is on part to the state-of-the-art ccsp approach that also uses data from other subjects. a potential advantage of our method is 2the kullback-leibler divergence between gaussians is defined as dkl(n0n1) = 1 2 ( tr ( 11 0 ) + (1  0)> 11 (1  0) ln ( det 0 det 1 )  k ) . fig. 1: application of multiple kernel learning to bci. the data integration task consists of combining different views on the data of interest. looking at the data through the lens of spatial filters extracted from other users provides a much richer picture of the data. the different sources of information are integrated by computing a kernel for each view and performing a weighted combination of them. the multiple kernel learning algorithm allows to simultaneously train the classifier and optimize the kernel weights j . 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 0 10 20 30 40 50 csp + lda error rate ccsp + lda error rate csp + svm error rate ccsp + svm error rate m k lc s p  e rr o r  ra te m k lc s p  e rr o r  ra te m k lc s p  e rr o r  ra te m k lc s p  e rr o r  ra te fig. 2: comparison of the error rates of our mklcsp method and the csp and covcsp baselines using an lda classifier or svm. each circle represents the test error of a subject and if the circle is below the solid line then our method is superior to the baseline. that it selects the importance of each subject by optimizing a criterion that is relevant for classification, whereas ccsp uses a similarity heuristic. furthermore we can control the sparsity of the solution by changing p. in the following we investigate the reasons for the im- proved performance of our method, i.e. the advantages of looking at the data through the lens of other subjects. spatial filters computed on other subjects performing the same motor imagery task may better capture the important information than filters extracted from the data of interest, especially if the data contains artefacts or is very scarce. in order to understand what information is transferred between subjects we analyse the mkl kernel weights and the similarity scores j of all subjects in fig. 3. the target subjects, i.e. the subjects whose motion intentions are decoded and classified, are shown on the rows, whereas users representing the additional sources of information are shown on the columns. we set the diagonal elements of the two matrices to zero for better visibility. in the case of mklcsp one can see that many users, e.g. the second one, prefer sparse mkl solutions and do not incorporate information from other subjects. on the other hand there are users that show some strong contributions from one or two subjects and yet others apply relatively small weights to all sources of information. note that the mkl weights do not correlate with the similarity values j which are shown in the right matrix. there is one subject (user 25) that seems to be very similar to other users, i.e. the divergence between his covariance matrix and the covariance matrices of other users is small. this means that his impact on the other participants is relatively large, however, note that the right matrix in fig. 3 only shows the similarity and not the final weights j . in order to investigate what makes a good and bad set of spatial filters we average the mkl weights over all subjects and visualize the activity patterns of the most attractive filters, i.e. the view with the largest average j , and the least attractive ones, i.e. the patterns that correspond to the kernel with smallest average j . the upper row of fig. 4 shows the activity patterns of the subject with the largest weight. one can clearly see that the first and fourth patterns show activity which is related to right and left hand motor imagery, thus it makes sense to apply the corresponding spatial filters to the data of interest. on the other hand the lower row of fig. 4 shows the patterns which were not so useful for the other subjects. note that these patterns are not very clean, thus they do not perform very well and were not selected by mklcsp. 0.04 0.08 0.12 0.16 0.2 other subjects t a rg e t  s u b je c ts mklcsp ccsp 0 fig. 3: mkl kernel weight j and similarity score j matrix. the rows represents the users of interest and the columns stand for the other sources of information. the weights selected by mkl do not correlate with the similarity scores, but are optimized with respect to the objective function of the classification problem. l a rg e s t   s m a lle s t   fig. 4: upper row: activity patterns of the subject that received the largest attention by mklcsp, i.e. the largest average weight j . the first and fourth pattern in the upper row shows clear motor imagery activity. lower row: activity patterns that received the lowest attention, i.e. the smallest average kernel weight. this set of patterns does not show the relevant activity. iv. discussion we showed that multiple kernel learning can be ap- plied to the data integration problem in bci. it does not rely on heuristics, but rather automatically determines the importance of other data sets in a way that is optimal for classification. using spatial filters computed on other subjects may significantly improve classification accuracy, however, weighting the data according to importance is crucial when using multi-subject approaches. in future research we would like to apply mkl to other data fusion problems in bci. for instance, the proposed method can be used to find the best combination of narrow frequency bands for a particular subject. in this case one would look at the data not from the lens of other users, but from the perspective of different frequency bands. first experiments show promising results. furthermore we plan to investigate the impact of the kernel on classification. as in computer vision we expect that brain-computer interfacing may profit from using non-linear classifiers. references [1] g. dornhege, j. del r. millan, t. hinterberger, d. mcfarland, and k.-r. muller, eds., toward brain-computer interfacing. cambridge, ma: mit press, 2007. [2] b. blankertz, r. tomioka, s. lemm, m. kawanabe, and k.-r. muller, optimizing spatial filters for robust eeg single-trial analysis, ieee signal proc. magazine, vol. 25, no. 1, pp. 4156, 2008. [3] f. lotte and c. guan, regularizing common spatial patterns to improve bci designs: unified theory and new algorithms, ieee trans. biomed. eng., vol. 58, no. 2, pp. 355 362, 2011. [4] w. samek, c. vidaurre, k.-r. muller, and m. kawanabe, stationary common spatial patterns for brain-computer interfacing, journal of neural engineering, vol. 9, no. 2, p. 026013, 2012. [5] h. kang, y. nam, and s. choi, composite common spatial pattern for subject-to-subject transfer, signal processing letters, ieee, vol. 16, no. 8, pp. 683 686, 2009. [6] r. tomioka and k.-r. muller, a regularized discriminative frame- work for eeg analysis with application to brain-computer interface, neuroimage, vol. 49, no. 1, pp. 415432, 2009. [7] f. lotte and c. guan, learning from other subjects helps reducing brain-computer interface calibration time, in icassp10: 35th ieee international conference on acoustics, speech, and signal processing, 2010, pp. 614617. [8] d. devlaminck, b. wyns, m. grosse-wentrup, g. otte, and p. santens, multi-subject learning for common spatial patterns in motor-imagery bci, computational intelligence and neuroscience, vol. 2011, no. 217987, pp. 19, 2011. [9] w. samek, f. c. meinecke, and k.-r. muller, transferring subspaces between subjects in brain-computer interfacing, ieee transactions on biomedical engineering, 2013, in press. [10] g. r. g. lanckriet, n. cristianini, p. bartlett, l. e. ghaoui, and m. i. jordan, learning the kernel matrix with semidefinite programming, j. of mach. learn. res., pp. 2772, 2004. [11] m. kloft, u. brefeld, s. sonnenburg, and a. zien, lp-norm multiple kernel learning, journal of machine learning research, vol. 12, pp. 953997, 2011. [12] a. binder, s. nakajima, m. kloft, c. muller, w. samek, u. brefeld, k.-r. muller, and m. kawanabe, insights from classifying visual concepts with multiple kernel learning, plos one, vol. 7, no. 8, p. e38897, 2012. [13] h.-p. huang, t.-h. huang, y.-h. liu, z.-h. kang, and j.-t. teng, a brain-controlled rehabilitation system with multiple kernel learning, in systems, man, and cybernetics (smc), 2011 ieee international conference on, oct. 2011, pp. 591 596. [14] c. j. c. burges, a tutorial on support vector machines for pattern recognition, data mining and knowledge discovery, vol. 2, pp. 121 167, 1998. [15] k.-r. muller, s. mika, g. ratsch, k. tsuda, and b. scholkopf, an introduction to kernel-based learning algorithms, ieee neural networks, vol. 12, no. 2, pp. 181201, may 2001. [16] m. kloft, u. brefeld, s. sonnenburg, p. laskov, k.-r. muller, and a. zien, efficient and accurate lp-norm multiple kernel learning, in advances in neural information processing systems 22. mit press, 2009, pp. 9971005. [17] g. dornhege, b. blankertz, g. curio, and k.-r. muller, boosting bit rates in noninvasive eeg single-trial classifications by feature combination and multiclass paradigms, ieee trans. biomed. eng., vol. 51, no. 6, pp. 993 1002, 2004. [18] s. fazli, f. popescu, m. danoczy, b. blankertz, k. muller, and c. grozea, subject-independent mental state classification in single trials, neural networks, vol. 22, no. 9, pp. 13051312, 2009. [19] s. fazli, m. danoczy, j. schelldorfer, and k.-r. muller, 1-penalized linear mixed-effects models for high dimensional data with application to bci, neuroimage, vol. 56, no. 4, pp. 2100  2108, 2011. [20] b. blankertz, c. sannelli, s. halder, e. m. hammer, a. kubler, k.-r. muller, g. curio, and t. dickhaus, neurophysiological predictor of smr-based bci performance, neuroimage, vol. 51, no. 4, pp. 1303 1309, 2010. '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertain_predictions_mask = (Y_test_predict > 0.4) & (Y_test_predict < 0.6)\n",
    "X_uncertain = X_test[uncertain_predictions_mask.flatten()]\n",
    "\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(df[\"full_text\"].values, df[\"topic\"].values,\n",
    "                                                                test_size=0.15, random_state=123)\n",
    "\n",
    "uncertain_papers = df_x_test[uncertain_predictions_mask.flatten()]\n",
    "print(\"Full text of uncertain prediction:\")\n",
    "uncertain_papers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 15s 5ms/sample - loss: 0.8814 - accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
